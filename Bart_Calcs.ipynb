{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ABAG Landuse Calculations for VTA and BART Model.\n",
    "\n",
    "This notebook documents the joining data between VTA or CCAG TAZ Zones and MTC's 1454 regions.  VTA and CCAG will be reffered to as Regional Partners. \n",
    "\n",
    "Also there is details on how to convert ABAG numbers to BART numbers.\n",
    "\n",
    "The inputs are the yearly calculations from MTC and VTA and CCAG.  The outputs are a csv, excel, and a shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#This uses geopy36\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "%matplotlib inline  \n",
    "from shapely.geometry import Point\n",
    "\n",
    "from simpledbf import Dbf5\n",
    "#pip install simpledbf\n",
    "#https://pypi.python.org/pypi/simpledbf/0.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RP stands for Regional Partner\n",
    "def prep_data(abag, rp_taz, geom_given = True):\n",
    "    \n",
    "    cols = ['TAZ','TAZ1454','DIST','SDIST','COUNTY','TOTHH','TOTPOP',\n",
    "                                    'HHPOP','EMPRES','HH1','HH2','HH3','HH4','TACRES','RESACRE','CIACRE','TEMP',\n",
    "                                    'RETEMP','SEREMP','OTHEMP','AGEMP','MANEMP','WHOEMP','AGE0004','AGE0519',\n",
    "                                    'AGE2044','AGE4564','AGE65','AGE0513','AGE1417','AGE1824','SFHH','MFHH', 'CITY']\n",
    "    cols_to_retain = ['INC1','INC2','INC3','INC4','MHHINC', 'ESENR', 'HSENR', 'COLLENR', 'COLLENRF', 'COLLENRP']\n",
    "\n",
    "    cols.extend(cols_to_retain)\n",
    "\n",
    "    if geom_given:\n",
    "        cols.append('geometry')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    rp_taz = rp_taz[cols].rename(columns={\"TOTHH\":\"RP_TOTHH\",\"TOTPOP\":\"RP_TOTPOP\",\n",
    "                                \"HHPOP\":\"RP_HHPOP\",\"EMPRES\":\"RP_EMPRES\",\"RESACRE\":'RP_RESACRE',\"CIACRE\":\"RP_CIACRE\",\"TEMP\":\"RP_TEMP\",\n",
    "                                         \"AGE0004\":\"RP_AGE0004\",\"AGE0519\":\"RP_AGE0519\",\"AGE2044\":\"RP_AGE2044\",\"AGE4564\":\"RP_AGE4564\",\"AGE65\":\"RP_AGE65\"})\n",
    "    #Clear out Student calc numbers where TOTPOP is 0.\n",
    "    criteria = \"RP_TOTPOP==0&(AGE0513>0|AGE1417>0|AGE1824>0)\"\n",
    "    rp_taz.loc[rp_taz.eval(criteria), 'AGE0513'] = 0\n",
    "    rp_taz.loc[rp_taz.eval(criteria), 'AGE1417'] = 0\n",
    "    rp_taz.loc[rp_taz.eval(criteria), 'AGE1824'] = 0\n",
    "    \n",
    "    #Calculation district wide average number of students to population ratio\n",
    "    okay_criteria = \"RP_TOTPOP>AGE0513+AGE1417+AGE1824\"\n",
    "    AGE0513_avg_factor =  (rp_taz.query(okay_criteria).groupby('DIST')['AGE0513'].sum()/rp_taz.query(okay_criteria).groupby('DIST')['RP_TOTPOP'].sum()).reset_index().rename(columns={0:'AGE0513_factor'})\n",
    "    AGE1417_avg_factor =  (rp_taz.query(okay_criteria).groupby('DIST')['AGE1417'].sum()/rp_taz.query(okay_criteria).groupby('DIST')['RP_TOTPOP'].sum()).reset_index().rename(columns={0:'AGE1417_factor'})    \n",
    "    AGE1824_avg_factor =  (rp_taz.query(okay_criteria).groupby('DIST')['AGE1824'].sum()/rp_taz.query(okay_criteria).groupby('DIST')['RP_TOTPOP'].sum()).reset_index().rename(columns={0:'AGE1824_factor'})\n",
    "    rp_taz = pd.merge(pd.merge(pd.merge(rp_taz, AGE0513_avg_factor),AGE1417_avg_factor),AGE1824_avg_factor)\n",
    "    \n",
    "    \n",
    "    # Save percentages for later calc\n",
    "    rp_taz['AGE0513_percent'] = rp_taz['AGE0513']/rp_taz['RP_TOTPOP']\n",
    "    rp_taz['AGE1417_percent'] = rp_taz['AGE1417']/rp_taz['RP_TOTPOP']\n",
    "    rp_taz['AGE1824_percent'] = rp_taz['AGE1824']/rp_taz['RP_TOTPOP']\n",
    "\n",
    "    #If the Total Population for the zone is below the student population, overwrite percentages with district factors.\n",
    "    bad_criteria = \"RP_TOTPOP<AGE0513+AGE1417+AGE1824\"\n",
    "    rp_taz.loc[rp_taz.eval(bad_criteria), 'AGE0513_percent'] = rp_taz.loc[rp_taz.eval(bad_criteria), 'AGE0513_factor']\n",
    "    rp_taz.loc[rp_taz.eval(bad_criteria), 'AGE1417_percent'] = rp_taz.loc[rp_taz.eval(bad_criteria), 'AGE1417_factor']\n",
    "    rp_taz.loc[rp_taz.eval(bad_criteria), 'AGE1824_percent'] = rp_taz.loc[rp_taz.eval(bad_criteria), 'AGE1824_factor']    \n",
    "    \n",
    "    #If the total population is greater than ten but the student population is 0, replace student percent with district average.\n",
    "    age_0513_bad_criteria = \"RP_TOTPOP>=10 & AGE0513==0\"\n",
    "    rp_taz.loc[rp_taz.eval(age_0513_bad_criteria), 'AGE0513_percent'] = rp_taz.loc[rp_taz.eval(age_0513_bad_criteria), 'AGE0513_factor']\n",
    "    age_1417_bad_criteria = \"RP_TOTPOP>=10 & AGE1417==0\"\n",
    "    rp_taz.loc[rp_taz.eval(age_1417_bad_criteria), 'AGE1417_percent'] = rp_taz.loc[rp_taz.eval(age_1417_bad_criteria), 'AGE1417_factor']\n",
    "    age_1824_bad_criteria = \"RP_TOTPOP>=10 & AGE1824==0\"\n",
    "    rp_taz.loc[rp_taz.eval(age_1824_bad_criteria), 'AGE1824_percent'] = rp_taz.loc[rp_taz.eval(age_1824_bad_criteria), 'AGE1824_factor']    \n",
    "    \n",
    "    #Join the RP shapefile to the abag 2010 dataset!  Pull this source input data directly from ABAG\n",
    "    rp_calc = pd.merge(abag[['TAZ1454','TOTHH','HHPOP','TOTPOP','EMPRES','HHINCQ1','HHINCQ2','HHINCQ3','HHINCQ4','RESACRE','CIACRE','TOTEMP','SHPOP62P','AGE0004','AGE0519',\n",
    "                                    'AGE2044','AGE4564','AGE65P']].rename(columns={\"SHPOP62P\":\"Z2SHARE\"}),\n",
    "                                rp_taz)\n",
    "\n",
    "    return rp_calc\n",
    "    # vt_calc.groupby(['TAZ1454','TAZ'])['VTA_TOTPOP'].apply(lambda x: x / x.sum())\n",
    "    # vt_calc.groupby(['TAZ1454','TAZ'])['VTA_TOTPOP'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def employment_cleaning(rp_calc):\n",
    "    sdist_totemp_sum = (rp_calc.groupby('SDIST')['RETEMP'].sum() + rp_calc.groupby('SDIST')['SEREMP'].sum() + rp_calc.groupby('SDIST')['OTHEMP'].sum() + rp_calc.groupby('SDIST')['AGEMP'].sum() + rp_calc.groupby('SDIST')['MANEMP'].sum() + rp_calc.groupby('SDIST')['WHOEMP'].sum())\n",
    "    a = (rp_calc.groupby('SDIST')['RETEMP'].sum()/sdist_totemp_sum).reset_index().rename(columns={0:'RETEMP_SDIST_AVG'})\n",
    "    b = (rp_calc.groupby('SDIST')['SEREMP'].sum()/sdist_totemp_sum).reset_index().rename(columns={0:'SEREMP_SDIST_AVG'})\n",
    "    c = (rp_calc.groupby('SDIST')['OTHEMP'].sum()/sdist_totemp_sum).reset_index().rename(columns={0:'OTHEMP_SDIST_AVG'})\n",
    "    d = (rp_calc.groupby('SDIST')['AGEMP'].sum()/sdist_totemp_sum).reset_index().rename(columns={0:'AGEMP_SDIST_AVG'})\n",
    "    e = (rp_calc.groupby('SDIST')['MANEMP'].sum()/sdist_totemp_sum).reset_index().rename(columns={0:'MANEMP_SDIST_AVG'})\n",
    "    f = (rp_calc.groupby('SDIST')['WHOEMP'].sum()/sdist_totemp_sum).reset_index().rename(columns={0:'WHOEMP_SDIST_AVG'})\n",
    "    dfs = [a,b,c,d,e,f]\n",
    "    from functools import reduce\n",
    "    EMP_AVG = reduce(lambda left,right: pd.merge(left,right), dfs)\n",
    "    rp_calc = pd.merge(rp_calc,EMP_AVG, how = 'left')    \n",
    "    bad_criteria = 'RP_TEMP >=5 & RETEMP + SEREMP + OTHEMP + AGEMP + MANEMP + WHOEMP == 0'\n",
    "    bad_criteria_spots = rp_calc.eval(bad_criteria)\n",
    "    rp_calc.loc[bad_criteria_spots,'RETEMP'] = rp_calc.loc[bad_criteria_spots,'RETEMP_SDIST_AVG']\n",
    "    rp_calc.loc[bad_criteria_spots,'SEREMP'] = rp_calc.loc[bad_criteria_spots,'SEREMP_SDIST_AVG']\n",
    "    rp_calc.loc[bad_criteria_spots,'OTHEMP'] = rp_calc.loc[bad_criteria_spots,'OTHEMP_SDIST_AVG']\n",
    "    rp_calc.loc[bad_criteria_spots,'RETEMP'] = rp_calc.loc[bad_criteria_spots,'RETEMP_SDIST_AVG']\n",
    "    rp_calc.loc[bad_criteria_spots,'RETEMP'] = rp_calc.loc[bad_criteria_spots,'RETEMP_SDIST_AVG']\n",
    "    rp_calc.loc[bad_criteria_spots,'RETEMP'] = rp_calc.loc[bad_criteria_spots,'RETEMP_SDIST_AVG']\n",
    "    return rp_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landuse_calcs(rp_calc):\n",
    "    \"\"\" Takes the input dataframe and does transformations, share calculations, to derive numbers for projections.\n",
    "    \"\"\"\n",
    "    rp_tothh = rp_calc.groupby(['TAZ1454','TAZ'])['RP_TOTHH'].sum().groupby(level = 0).transform(lambda x: x/x.sum()).reset_index()\n",
    "    rp_hhpop = rp_calc.groupby(['TAZ1454','TAZ'])['RP_HHPOP'].sum().groupby(level = 0).transform(lambda x: x/x.sum()).reset_index()\n",
    "    rp_totpop = rp_calc.groupby(['TAZ1454','TAZ'])['RP_TOTPOP'].sum().groupby(level = 0).transform(lambda x: x/x.sum()).reset_index()\n",
    "    rp_empres = rp_calc.groupby(['TAZ1454','TAZ'])['RP_EMPRES'].sum().groupby(level = 0).transform(lambda x: x/x.sum()).reset_index()\n",
    "\n",
    "    rp_resacre = rp_calc.groupby(['TAZ1454','TAZ'])['RP_RESACRE'].sum().groupby(level = 0).transform(lambda x: x/x.sum()).reset_index()\n",
    "    rp_ciacre = rp_calc.groupby(['TAZ1454','TAZ'])['RP_CIACRE'].sum().groupby(level = 0).transform(lambda x: x/x.sum()).reset_index()\n",
    "    rp_temp = rp_calc.groupby(['TAZ1454','TAZ'])['RP_TEMP'].sum().groupby(level = 0).transform(lambda x: x/x.sum()).reset_index()\n",
    "\n",
    "    rp_tothh = rp_tothh.rename(columns={\"RP_TOTHH\":\"RP_TOTHH_share\"})\n",
    "    rp_hhpop = rp_hhpop.rename(columns={\"RP_HHPOP\":\"RP_HHPOP_share\"})\n",
    "    rp_totpop = rp_totpop.rename(columns={\"RP_TOTPOP\":\"RP_TOTPOP_share\"})\n",
    "    rp_empres = rp_empres.rename(columns={\"RP_EMPRES\":\"RP_EMPRES_share\"})\n",
    "\n",
    "    rp_resacre = rp_resacre.rename(columns={\"RP_RESACRE\":\"RP_RESACRE_share\"})\n",
    "    rp_ciacre = rp_ciacre.rename(columns={\"RP_CIACRE\":\"RP_CIACRE_share\"})\n",
    "    rp_temp = rp_temp.rename(columns={\"RP_TEMP\":\"RP_TEMP_share\"})\n",
    "\n",
    "    vta_final= pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(rp_calc,rp_tothh),rp_hhpop),rp_totpop),rp_empres),rp_resacre),rp_ciacre),rp_temp)\n",
    "    vta_final['abag_TOTHH_dist'] = vta_final['TOTHH']*vta_final['RP_TOTHH_share']\n",
    "    vta_final['abag_HHPOP_dist'] = vta_final['HHPOP']*vta_final['RP_HHPOP_share']\n",
    "    vta_final['abag_TOTPOP_dist'] = vta_final['TOTPOP']*vta_final['RP_TOTPOP_share']\n",
    "    vta_final['abag_EMPRES_dist'] = vta_final['EMPRES']*vta_final['RP_EMPRES_share']\n",
    "    \n",
    "    vta_final['abag_RESACRE_dist'] = round(vta_final['RESACRE']*vta_final['RP_RESACRE_share'])\n",
    "    vta_final['abag_CIACRE_dist'] = round(vta_final['CIACRE']*vta_final['RP_CIACRE_share'])\n",
    "    vta_final['abag_TEMP_dist'] = round(vta_final['TOTEMP']*vta_final['RP_TEMP_share'])\n",
    "\n",
    "#     vta_final['abag_HHPOP_dist'] = round(vta_final['RP_HHPOP']/vta_final['RP_TOTHH']*vta_final['abag_TOTHH_dist'])\n",
    "    \n",
    "#     vta_final['abag_TOTPOP_dist'] = round(vta_final['RP_TOTPOP']/vta_final['RP_TOTHH']*vta_final['abag_TOTHH_dist'])\n",
    "\n",
    "#     vta_final['abag_EMPRES_dist'] = round(vta_final['RP_EMPRES']/vta_final['RP_TOTHH']*vta_final['abag_TOTHH_dist'])\n",
    "\n",
    "    #Make HH\n",
    "    vta_final['abag_HH1_dist'] =round(vta_final['HH1']/(vta_final['HH1'] + vta_final['HH2'] + vta_final['HH3'] + vta_final['HH4'])*vta_final['abag_TOTHH_dist'])\n",
    "    vta_final['abag_HH2_dist'] =round(vta_final['HH2']/(vta_final['HH1'] + vta_final['HH2'] + vta_final['HH3'] + vta_final['HH4'])*vta_final['abag_TOTHH_dist'])\n",
    "    vta_final['abag_HH3_dist'] =round(vta_final['HH3']/(vta_final['HH1'] + vta_final['HH2'] + vta_final['HH3'] + vta_final['HH4'])*vta_final['abag_TOTHH_dist'])\n",
    "    vta_final['abag_HH4_dist'] =round(vta_final['HH4']/(vta_final['HH1'] + vta_final['HH2'] + vta_final['HH3'] + vta_final['HH4'])*vta_final['abag_TOTHH_dist'])\n",
    "\n",
    "#     vta_final['abag_RETEMP_dist'] = round(vta_final['RETEMP']/vta_final['RP_TEMP']*vta_final['abag_TEMP_dist'])\n",
    "    vta_final['abag_RETEMP_dist'] = round(vta_final['RETEMP']/(vta_final['RETEMP'] + vta_final['SEREMP'] + vta_final['OTHEMP'] + vta_final['AGEMP'] + vta_final['MANEMP'] + vta_final['WHOEMP'])*vta_final['abag_TEMP_dist'])\n",
    "    vta_final['abag_SEREMP_dist'] = round(vta_final['SEREMP']/(vta_final['RETEMP'] + vta_final['SEREMP'] + vta_final['OTHEMP'] + vta_final['AGEMP'] + vta_final['MANEMP'] + vta_final['WHOEMP'])*vta_final['abag_TEMP_dist'])\n",
    "    vta_final['abag_OTHEMP_dist'] = round(vta_final['OTHEMP']/(vta_final['RETEMP'] + vta_final['SEREMP'] + vta_final['OTHEMP'] + vta_final['AGEMP'] + vta_final['MANEMP'] + vta_final['WHOEMP'])*vta_final['abag_TEMP_dist'])\n",
    "    vta_final['abag_AGEMP_dist'] = round(vta_final['AGEMP']/(vta_final['RETEMP'] + vta_final['SEREMP'] + vta_final['OTHEMP'] + vta_final['AGEMP'] + vta_final['MANEMP'] + vta_final['WHOEMP'])*vta_final['abag_TEMP_dist'])\n",
    "    vta_final['abag_MANEMP_dist'] = round(vta_final['MANEMP']/(vta_final['RETEMP'] + vta_final['SEREMP'] + vta_final['OTHEMP'] + vta_final['AGEMP'] + vta_final['MANEMP'] + vta_final['WHOEMP'])*vta_final['abag_TEMP_dist'])\n",
    "    vta_final['abag_WHOEMP_dist'] = round(vta_final['WHOEMP']/(vta_final['RETEMP'] + vta_final['SEREMP'] + vta_final['OTHEMP'] + vta_final['AGEMP'] + vta_final['MANEMP'] + vta_final['WHOEMP'])*vta_final['abag_TEMP_dist'])\n",
    "\n",
    "    vta_final['abag_AGE0004_dist'] = round(vta_final['RP_AGE0004']/(vta_final['RP_AGE0004'] + vta_final['RP_AGE0519'] + vta_final['RP_AGE2044'] + vta_final['RP_AGE4564'] + vta_final['RP_AGE65'])*vta_final['abag_TOTPOP_dist'])\n",
    "    vta_final['abag_AGE0519_dist'] = round(vta_final['RP_AGE0519']/(vta_final['RP_AGE0004'] + vta_final['RP_AGE0519'] + vta_final['RP_AGE2044'] + vta_final['RP_AGE4564'] + vta_final['RP_AGE65'])*vta_final['abag_TOTPOP_dist'])\n",
    "    vta_final['abag_AGE2044_dist'] = round(vta_final['RP_AGE2044']/(vta_final['RP_AGE0004'] + vta_final['RP_AGE0519'] + vta_final['RP_AGE2044'] + vta_final['RP_AGE4564'] + vta_final['RP_AGE65'])*vta_final['abag_TOTPOP_dist'])\n",
    "    vta_final['abag_AGE4564_dist'] = round(vta_final['RP_AGE4564']/(vta_final['RP_AGE0004'] + vta_final['RP_AGE0519'] + vta_final['RP_AGE2044'] + vta_final['RP_AGE4564'] + vta_final['RP_AGE65'])*vta_final['abag_TOTPOP_dist'])\n",
    "    vta_final['abag_AGE65_dist'] = round(vta_final['RP_AGE65']/(vta_final['RP_AGE0004'] + vta_final['RP_AGE0519'] + vta_final['RP_AGE2044'] + vta_final['RP_AGE4564'] + vta_final['RP_AGE65'])*vta_final['abag_TOTPOP_dist'])\n",
    "\n",
    "    vta_final['abag_AGE0513_dist'] = round(vta_final['AGE0513_percent']*vta_final['abag_TOTPOP_dist'])\n",
    "    vta_final['abag_AGE1417_dist'] = round(vta_final['AGE1417_percent']*vta_final['abag_TOTPOP_dist'])\n",
    "    vta_final['abag_AGE1824_dist'] = round(vta_final['AGE1824_percent']*vta_final['abag_TOTPOP_dist'])\n",
    "    \n",
    "    vta_final['abag_SFHH_dist'] = round(vta_final['SFHH']/(vta_final['SFHH'] + vta_final['MFHH'])*vta_final['abag_TOTHH_dist'])\n",
    "    vta_final['abag_MFHH_dist'] = round(vta_final['MFHH']/(vta_final['SFHH'] + vta_final['MFHH'])*vta_final['abag_TOTHH_dist'])\n",
    "\n",
    "    bad_criteria = \"abag_HHPOP_dist > abag_TOTPOP_dist\"\n",
    "    vta_final.loc[vta_final.eval(bad_criteria), 'abag_HHPOP_dist'] = vta_final.loc[vta_final.eval(bad_criteria), 'abag_TOTPOP_dist']\n",
    "\n",
    "    bad_criteria = \"abag_EMPRES_dist > abag_HHPOP_dist\"\n",
    "    vta_final.loc[vta_final.eval(bad_criteria), 'abag_EMPRES_dist'] = vta_final.loc[vta_final.eval(bad_criteria), 'abag_HHPOP_dist']\n",
    "    \n",
    "    bad_criteria = \"abag_TOTHH_dist > 0 & abag_HHPOP_dist == 0 & TAZ <= 1490\"\n",
    "    city_hhpop_tothh_average = (vta_final.groupby([\"CITY\"])['abag_HHPOP_dist'].sum() / vta_final.groupby([\"CITY\"])['abag_TOTHH_dist'].sum()).reset_index().rename(columns={0:'HHPOP/TOTHH'})\n",
    "    vta_final = pd.merge(vta_final, city_hhpop_tothh_average, how = 'left')\n",
    "    vta_final.loc[vta_final.eval(bad_criteria), 'abag_TOTPOP_dist'] = vta_final.loc[vta_final.eval(bad_criteria), 'abag_TOTHH_dist']*vta_final.loc[vta_final.eval(bad_criteria), 'HHPOP/TOTHH']\n",
    "    vta_final.loc[vta_final.eval(bad_criteria), 'abag_HHPOP_dist'] = vta_final.loc[vta_final.eval(bad_criteria), 'abag_TOTHH_dist']*vta_final.loc[vta_final.eval(bad_criteria), 'HHPOP/TOTHH']\n",
    "\n",
    "    bad_criteria = \"abag_TOTHH_dist > 0 & abag_HHPOP_dist == 0 & TAZ > 1490\"    \n",
    "    sdist_hhpop_tothh_average = (vta_final.groupby([\"SDIST\"])['abag_HHPOP_dist'].sum() / vta_final.groupby([\"SDIST\"])['abag_TOTHH_dist'].sum()).reset_index().rename(columns={0:'SD_HHPOP/TOTHH'})\n",
    "    vta_final = pd.merge(vta_final, sdist_hhpop_tothh_average, how = 'left')\n",
    "    vta_final.loc[vta_final.eval(bad_criteria), 'abag_TOTPOP_dist'] = vta_final.loc[vta_final.eval(bad_criteria), 'abag_TOTHH_dist']*vta_final.loc[vta_final.eval(bad_criteria), 'SD_HHPOP/TOTHH']\n",
    "    vta_final.loc[vta_final.eval(bad_criteria), 'abag_HHPOP_dist'] = vta_final.loc[vta_final.eval(bad_criteria), 'abag_TOTHH_dist']*vta_final.loc[vta_final.eval(bad_criteria), 'SD_HHPOP/TOTHH']\n",
    "    \n",
    "    vta_final = vta_final.round({'abag_TOTHH_dist': 0, 'abag_HHPOP_dist': 0, 'abag_TOTPOP_dist': 0, 'abag_EMPRES_dist': 0})\n",
    "    \n",
    "    return vta_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STFID</th>\n",
       "      <th>FIPSSTCO</th>\n",
       "      <th>TRACT2</th>\n",
       "      <th>TRACT</th>\n",
       "      <th>TRACTID</th>\n",
       "      <th>SUPERD</th>\n",
       "      <th>TAZ1454</th>\n",
       "      <th>AREALAND</th>\n",
       "      <th>AREAWATR</th>\n",
       "      <th>LANDACRE</th>\n",
       "      <th>...</th>\n",
       "      <th>HHPOP</th>\n",
       "      <th>TOTPOP</th>\n",
       "      <th>EMPRES</th>\n",
       "      <th>AGE0004</th>\n",
       "      <th>AGE0519</th>\n",
       "      <th>AGE2044</th>\n",
       "      <th>AGE4564</th>\n",
       "      <th>AGE65P</th>\n",
       "      <th>total_job_spaces</th>\n",
       "      <th>total_residential_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06001400100</td>\n",
       "      <td>06001</td>\n",
       "      <td>400100</td>\n",
       "      <td>400100</td>\n",
       "      <td>4001</td>\n",
       "      <td>19</td>\n",
       "      <td>1005</td>\n",
       "      <td>6799198</td>\n",
       "      <td>0</td>\n",
       "      <td>1680.118487</td>\n",
       "      <td>...</td>\n",
       "      <td>3027.0</td>\n",
       "      <td>3029.0</td>\n",
       "      <td>2086.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>1312.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>3344.0</td>\n",
       "      <td>1399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06001400200</td>\n",
       "      <td>06001</td>\n",
       "      <td>400200</td>\n",
       "      <td>400200</td>\n",
       "      <td>4002</td>\n",
       "      <td>19</td>\n",
       "      <td>999</td>\n",
       "      <td>659615</td>\n",
       "      <td>0</td>\n",
       "      <td>162.994423</td>\n",
       "      <td>...</td>\n",
       "      <td>1928.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>6134.0</td>\n",
       "      <td>909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06001400300</td>\n",
       "      <td>06001</td>\n",
       "      <td>400300</td>\n",
       "      <td>400300</td>\n",
       "      <td>4003</td>\n",
       "      <td>19</td>\n",
       "      <td>998</td>\n",
       "      <td>1074640</td>\n",
       "      <td>0</td>\n",
       "      <td>265.549338</td>\n",
       "      <td>...</td>\n",
       "      <td>5284.0</td>\n",
       "      <td>5325.0</td>\n",
       "      <td>3906.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>1473.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>2087.0</td>\n",
       "      <td>2754.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06001400400</td>\n",
       "      <td>06001</td>\n",
       "      <td>400400</td>\n",
       "      <td>400400</td>\n",
       "      <td>4004</td>\n",
       "      <td>19</td>\n",
       "      <td>1000</td>\n",
       "      <td>696057</td>\n",
       "      <td>0</td>\n",
       "      <td>171.999438</td>\n",
       "      <td>...</td>\n",
       "      <td>3711.0</td>\n",
       "      <td>3746.0</td>\n",
       "      <td>2609.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>1918.0</td>\n",
       "      <td>977.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>1862.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06001400500</td>\n",
       "      <td>06001</td>\n",
       "      <td>400500</td>\n",
       "      <td>400500</td>\n",
       "      <td>4005</td>\n",
       "      <td>19</td>\n",
       "      <td>1001</td>\n",
       "      <td>576343</td>\n",
       "      <td>0</td>\n",
       "      <td>142.417463</td>\n",
       "      <td>...</td>\n",
       "      <td>3423.0</td>\n",
       "      <td>3556.0</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>1737.0</td>\n",
       "      <td>815.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>1662.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         STFID FIPSSTCO  TRACT2   TRACT TRACTID  SUPERD  TAZ1454  AREALAND  \\\n",
       "0  06001400100    06001  400100  400100    4001      19     1005   6799198   \n",
       "1  06001400200    06001  400200  400200    4002      19      999    659615   \n",
       "2  06001400300    06001  400300  400300    4003      19      998   1074640   \n",
       "3  06001400400    06001  400400  400400    4004      19     1000    696057   \n",
       "4  06001400500    06001  400500  400500    4005      19     1001    576343   \n",
       "\n",
       "   AREAWATR     LANDACRE           ...              HHPOP  TOTPOP  EMPRES  \\\n",
       "0         0  1680.118487           ...             3027.0  3029.0  2086.0   \n",
       "1         0   162.994423           ...             1928.0  2002.0  1403.0   \n",
       "2         0   265.549338           ...             5284.0  5325.0  3906.0   \n",
       "3         0   171.999438           ...             3711.0  3746.0  2609.0   \n",
       "4         0   142.417463           ...             3423.0  3556.0  2280.0   \n",
       "\n",
       "   AGE0004  AGE0519  AGE2044  AGE4564  AGE65P  total_job_spaces  \\\n",
       "0    119.0    249.0    799.0   1312.0   550.0            3344.0   \n",
       "1     92.0    179.0    833.0    674.0   224.0            6134.0   \n",
       "2    282.0    444.0   2592.0   1473.0   534.0            2087.0   \n",
       "3    175.0    337.0   1918.0    977.0   339.0            1434.0   \n",
       "4    171.0    430.0   1737.0    815.0   403.0             898.0   \n",
       "\n",
       "   total_residential_units  \n",
       "0                   1399.0  \n",
       "1                    909.0  \n",
       "2                   2754.0  \n",
       "3                   1862.0  \n",
       "4                   1662.0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepping the MTC data\n",
    "mtc_taz = gpd.read_file('MTC/')\n",
    "abag = pd.read_csv('ABAG_03202018/run7224c_taz_summaries_2015.csv')\n",
    "abag = abag.rename(columns={'ZONE':'TAZ1454'})\n",
    "mtc_taz = pd.merge(mtc_taz,abag)\n",
    "\n",
    "mtc_taz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HHINCQ1 - number of houses in the 1st quartile.\n",
    "mtc_taz.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtc_taz.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep the VTA data\n",
    "\n",
    "vta_taz = gpd.read_file('VTA_TAZ/')\n",
    "# vta_taz = vta_taz.rename(columns={'TAZ':'VTA_TAZ'})\n",
    "\n",
    "dbf = Dbf5('2017ABAGLanduseAllocation/VTA/zmast13.dbf')\n",
    "vta_dbf = dbf.to_dataframe()\n",
    "vta_dbf = vta_dbf.rename(columns={'ZONE':'TAZ'})\n",
    "vta_taz = pd.merge(vta_taz,vta_dbf)\n",
    "\n",
    "\n",
    "# mtc_taz = gpd.read_file('/Users/vivek/Github/VTA/Landuse/MTC/MTCTAZ1454.dbf')\n",
    "\n",
    "\n",
    "#http://analytics.mtc.ca.gov/foswiki/UrbanSimTwo/OutputToTravelModel\n",
    "\n",
    "# vta_taz['centroid'] = vta_taz.centroid\n",
    "# vta_taz = vta_taz.set_geometry('centroid')\n",
    "# vta_taz['old_geometry'] = vta_taz['geometry']\n",
    "# vta_taz['geometry'] = vta_taz['centroid']\n",
    "\n",
    "# centroid = gpd.sjoin(mtc_taz[['TAZ1454','geometry']], vta_taz, how = \"right\", op='contains')\n",
    "# centroid['TAZ1454'].nunique()\n",
    "# centroid[['TAZ1454','TAZ']].to_csv(\"rel.csv\")\n",
    "# rel = centroid[['TAZ1454','TAZ']]\n",
    "# missing_zones = pd.DataFrame([{'TAZ1454' : 1454, 'TAZ' : 2786},{'TAZ1454':404,'TAZ':980},{'TAZ1454' : 190, 'TAZ' : 1890}])\n",
    "# rel = pd.concat([rel,missing_zones])\n",
    "# rel.to_csv('rel_vta_mtc.csv',index=False)\n",
    "\n",
    "rel = pd.read_csv('rel_vta_mtc.csv')\n",
    "rel = rel.loc[~rel['TAZ1454'].isnull(),]\n",
    "\n",
    "vta_taz = pd.merge(vta_taz[['TAZ','DIST','SDIST','COUNTY','geometry','TOTHH','TOTPOP',\n",
    "                            'HHPOP','EMPRES','HH1','HH2','HH3','HH4','TACRES','RESACRE','CIACRE','TEMP',\n",
    "                            'RETEMP','SEREMP','OTHEMP','AGEMP','MANEMP','WHOEMP','AGE0004','AGE0519',\n",
    "                            'AGE2044','AGE4564','AGE65','SFHH','MFHH']],rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep Data for CCAG\n",
    "\n",
    "# CCAG_taz = gpd.read_file('CCAGTAZ/')\n",
    "\n",
    "# Not sure what the data in the TAZ shapefile relates to, will delete.\n",
    "# del CCAG_taz['ESENR']\n",
    "# del CCAG_taz['HSENR']\n",
    "# CCAG_taz.rename(columns={'CITY':'CITY_NAME'}, inplace=True)\n",
    "years = ['2015','2020','2025','2030','2035','2040']\n",
    "\n",
    "dbf = Dbf5('CCAG/Zmast15.dbf')\n",
    "ccag_dbf = dbf.to_dataframe()\n",
    "ccag_extra_counties = ccag_dbf.query(\"COUNTY==10|COUNTY==11|COUNTY==12|COUNTY==13\")\n",
    "ccag_dbf.rename(columns={'ZONE':'TAZ'}, inplace=True)\n",
    "\n",
    "ccag_correspondence = pd.read_excel('CCAG/CCAGTAZ-to-MTC1454-for-Vivek.xlsx', sheet_name='CCAGTAZ-MTC1454-Corresp')\n",
    "ccag_correspondence.rename(columns={'CCAGTAZ':'TAZ','MTCTAZ1454':'TAZ1454'}, inplace=True)\n",
    "ccag_df = pd.merge(ccag_dbf, ccag_correspondence[['TAZ','TAZ1454']], left_on = ['TAZ'], right_on = ['TAZ'])\n",
    "\n",
    "sc_city_corr = pd.read_excel('SSC_TAZ_to_City_Correspondence.xlsx')\n",
    "sc_city_corr.rename(columns={'BART_ZONE':'TAZ'}, inplace=True)\n",
    "ccag_df = pd.merge(ccag_df,sc_city_corr, how = 'left')\n",
    "\n",
    "\n",
    "for year in years:\n",
    "\n",
    "    abag = pd.read_csv('ABAG_03202018/run7224c_taz_summaries_' + year + '.csv')\n",
    "    abag = abag.rename(columns={'ZONE':'TAZ1454'})\n",
    "    #     mtc_taz = pd.merge(mtc_taz,abag)\n",
    "\n",
    "    rp_calc = prep_data(abag, ccag_df, geom_given = False)\n",
    "\n",
    "    pairs = [('RP_TOTHH','TOTHH'),('RP_HHPOP','HHPOP'),('RP_TOTPOP','TOTPOP'),\n",
    "             ('RP_EMPRES','EMPRES'),\n",
    "             ('RP_RESACRE','RESACRE'),('RP_CIACRE','CIACRE'),('RP_TEMP','TOTEMP')]\n",
    "    for pair in pairs:\n",
    "        rp_calc.loc[rp_calc.query(\"COUNTY!=3&COUNTY!=2\").index,pair[0]] = rp_calc.loc[rp_calc.query(\"COUNTY!=3&COUNTY!=2\").index,pair[1]]\n",
    "\n",
    "    pairs = [('HH1','HHINCQ1'),('HH2','HHINCQ2'),('HH3','HHINCQ3'),('HH4','HHINCQ4'),\n",
    "             ('RP_AGE0004','AGE0004'),('RP_AGE0519','AGE0519'),('RP_AGE2044','AGE2044'),('RP_AGE4564','AGE4564'),('RP_AGE65','AGE65P')\n",
    "            ]\n",
    "    for pair in pairs:\n",
    "        rp_calc.loc[rp_calc.index,pair[0]] = rp_calc.loc[rp_calc.index,pair[1]]\n",
    "        \n",
    "    rp_calc = employment_cleaning(rp_calc)        \n",
    "        \n",
    "    ccag_calcs = landuse_calcs(rp_calc)\n",
    "    ccag_calcs = ccag_calcs.sort_values(by='TAZ')\n",
    "\n",
    "    ccag_calcs.to_csv('output/ccag_proj_abag_calcs_' + year + '.csv',index=False)\n",
    "\n",
    "    ccag_calcs_final = ccag_calcs[['TAZ', 'DIST', 'SDIST', 'COUNTY', 'abag_TOTHH_dist', 'abag_HHPOP_dist',\n",
    "           'abag_TOTPOP_dist', 'abag_EMPRES_dist', 'abag_SFHH_dist', 'abag_MFHH_dist', 'abag_HH1_dist', 'abag_HH2_dist', 'abag_HH3_dist', 'abag_HH4_dist',\n",
    "           'INC1', 'INC2', 'INC3', 'INC4', 'MHHINC', 'TACRES', 'abag_RESACRE_dist',\n",
    "           'abag_CIACRE_dist', 'Z2SHARE', 'abag_TEMP_dist', 'abag_RETEMP_dist', 'abag_SEREMP_dist', 'abag_OTHEMP_dist', 'abag_AGEMP_dist',\n",
    "           'abag_MANEMP_dist', 'abag_WHOEMP_dist', 'abag_AGE0004_dist', 'abag_AGE0519_dist', 'abag_AGE2044_dist', 'abag_AGE4564_dist',\n",
    "           'abag_AGE65_dist', 'abag_AGE0513_dist', 'abag_AGE1417_dist', 'abag_AGE1824_dist', 'ESENR', 'HSENR',\n",
    "           'COLLENR', 'COLLENRF', 'COLLENRP','TAZ1454']].rename(columns={'TAZ':'ZONE'})\n",
    "\n",
    "    ccag_calcs_final.rename(columns=lambda x: x.replace('abag_','').replace('_dist',''),inplace=True)\n",
    "\n",
    "    del ccag_calcs_final['TAZ1454']\n",
    "    col_order = ccag_calcs_final.columns\n",
    "    ccag_calcs_final_appended = ccag_calcs_final.append(ccag_extra_counties)[col_order]\n",
    "\n",
    "    ccag_calcs_final_appended.to_csv('output/ccag_calcs_clean' + year + '.csv',na_rep=0,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vivek/anaconda3/envs/GIS/lib/python3.6/site-packages/pandas/core/frame.py:3027: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n",
      "2025\n",
      "2030\n",
      "2035\n",
      "2040\n"
     ]
    }
   ],
   "source": [
    "#Prep ABAG data\n",
    "#BART: Update abag projection to new file.\n",
    "\n",
    "# mtc_taz = gpd.read_file('MTC/')\n",
    "# mtc_taz = mtc_taz.rename(columns={'TAZ1454':'ZONE'})\n",
    "years = ['2015','2020','2025','2030','2035','2040']\n",
    "\n",
    "#Prep BART data\n",
    "\n",
    "# bart_dbf = pd.read_excel('bart_calcs_clean2015_AvdH_corrected.xlsx', sheet_name='Corrected')\n",
    "# year = '2015'\n",
    "\n",
    "# This might be inefficient since the relationship seems to be inside the bart_TAZ shapefile.\n",
    "# bart_taz = gpd.read_file('BART-TAZ/TAZ/')\n",
    "# bart_crs = bart_taz.crs\n",
    "# bart_taz = pd.merge(bart_taz[['TAZ','KEY','AREA', 'geometry']],bart_dbf)\n",
    "\n",
    "for year in years:\n",
    "\n",
    "    if(year in ['2015','2020','2025','2030']):\n",
    "        print(year)\n",
    "        bart_dbf = pd.read_csv('bart_calcs_clean2015_AvdH_input.csv')\n",
    "        bart_extra_counties = bart_dbf.query(\"COUNTY==10|COUNTY==11|COUNTY==12|COUNTY==13\")\n",
    "        bart_extra_counties.rename(columns={'TAZ':'ZONE'},inplace=True)\n",
    "\n",
    "        bart_dbf = bart_dbf.rename(columns={'ZONE':'TAZ'})\n",
    "        bart_dbf['EMPRES'] = bart_dbf['EMPRES'].replace(to_replace={'#REF!':'1'}).astype(int)\n",
    "\n",
    "    elif(year in ['2035','2040']):\n",
    "        print(year)\n",
    "        bart_dbf = pd.read_excel('BART_2025_2035_clean_landuse_data.xlsx', sheet_name='ZMAST35')\n",
    "        bart_extra_counties = bart_dbf.query(\"COUNTY==10|COUNTY==11|COUNTY==12|COUNTY==13\")\n",
    "        bart_extra_counties.rename(columns={'TAZ':'ZONE'},inplace=True)\n",
    "\n",
    "        bart_dbf = bart_dbf.rename(columns={'ZONE':'TAZ'})\n",
    "        bart_rel = pd.read_excel('BART_zmast15_EIR.xlsx', sheet_name='Zone Corresp')\n",
    "        bart_rel = bart_rel.rename(columns={'BARTZONE':'TAZ', 'MTCTAZ':'TAZ1454'})\n",
    "        bart_dbf = pd.merge(bart_dbf, bart_rel)\n",
    "\n",
    "    sc_city_corr = pd.read_excel('SSC_TAZ_to_City_Correspondence.xlsx')\n",
    "    sc_city_corr.rename(columns={'BART_ZONE':'TAZ'}, inplace=True)\n",
    "    bart_dbf = pd.merge(bart_dbf,sc_city_corr, how = 'left')\n",
    "    \n",
    "    abag = pd.read_csv('ABAG_03202018/run7224c_taz_summaries_' + year + '.csv')\n",
    "    abag = abag.rename(columns={'ZONE':'TAZ1454'})\n",
    "    #     mtc_taz = pd.merge(mtc_taz,abag)\n",
    "\n",
    "    rp_calc = prep_data(abag, bart_dbf, geom_given = False)\n",
    "\n",
    "    # Copy over values for the area that is not in the SC county or chosen region to cover up errors in the input files.\n",
    "    pairs = [('RP_TOTHH','TOTHH'),('RP_HHPOP','HHPOP'),('RP_TOTPOP','TOTPOP'),\n",
    "             ('RP_EMPRES','EMPRES'),\n",
    "             ('RP_RESACRE','RESACRE'),('RP_CIACRE','CIACRE'),('RP_TEMP','TOTEMP')]\n",
    "    for pair in pairs:\n",
    "        rp_calc.loc[rp_calc.query(\"COUNTY!=3\").index,pair[0]] = rp_calc.loc[rp_calc.query(\"COUNTY!=3\").index,pair[1]]\n",
    "\n",
    "    pairs = [('HH1','HHINCQ1'),('HH2','HHINCQ2'),('HH3','HHINCQ3'),('HH4','HHINCQ4'),\n",
    "             ('RP_AGE0004','AGE0004'),('RP_AGE0519','AGE0519'),('RP_AGE2044','AGE2044'),('RP_AGE4564','AGE4564'),('RP_AGE65','AGE65P')\n",
    "            ]\n",
    "    for pair in pairs:\n",
    "        rp_calc.loc[rp_calc.index,pair[0]] = rp_calc.loc[rp_calc.index,pair[1]]\n",
    "\n",
    "    rp_calc = employment_cleaning(rp_calc)        \n",
    "       \n",
    "    bart_calcs = landuse_calcs(rp_calc)\n",
    "    bart_calcs = bart_calcs.sort_values(by='TAZ')\n",
    "    # del bart_calcs['geometry']\n",
    "    bart_calcs.to_csv('output/bart_proj_abag_calcs_' + year + '.csv',index=False)\n",
    "#     bart_calcs.to_excel('output/bart_proj_abag_calcs_'  + year + '.xlsx' ,index=False)\n",
    "\n",
    "    bart_calcs_final = bart_calcs[['TAZ', 'DIST', 'SDIST', 'COUNTY', 'abag_TOTHH_dist', 'abag_HHPOP_dist',\n",
    "           'abag_TOTPOP_dist', 'abag_EMPRES_dist', 'abag_SFHH_dist', 'abag_MFHH_dist', 'abag_HH1_dist', 'abag_HH2_dist', 'abag_HH3_dist', 'abag_HH4_dist',\n",
    "           'INC1', 'INC2', 'INC3', 'INC4', 'MHHINC', 'TACRES', 'abag_RESACRE_dist',\n",
    "           'abag_CIACRE_dist', 'Z2SHARE', 'abag_TEMP_dist', 'abag_RETEMP_dist', 'abag_SEREMP_dist', 'abag_OTHEMP_dist', 'abag_AGEMP_dist',\n",
    "           'abag_MANEMP_dist', 'abag_WHOEMP_dist', 'abag_AGE0004_dist', 'abag_AGE0519_dist', 'abag_AGE2044_dist', 'abag_AGE4564_dist',\n",
    "           'abag_AGE65_dist', 'abag_AGE0513_dist', 'abag_AGE1417_dist', 'abag_AGE1824_dist', 'ESENR', 'HSENR',\n",
    "           'COLLENR', 'COLLENRF', 'COLLENRP','TAZ1454']].rename(columns={'TAZ':'ZONE'})\n",
    "\n",
    "    # https://www.dataquest.io/blog/pandas-cheat-sheet/\n",
    "    bart_calcs_final.rename(columns=lambda x: x.replace('abag_','').replace('_dist',''),inplace=True)\n",
    "\n",
    "    del bart_calcs_final['TAZ1454']\n",
    "    col_order = bart_calcs_final.columns\n",
    "    bart_calcs_appended = bart_calcs_final.append(bart_extra_counties)[col_order]\n",
    "    \n",
    "    bart_calcs_appended.to_csv('output/bart_calcs_clean' + year + '.csv',na_rep=0,index=False)\n",
    "#     bart_calcs_final.to_excel('output/bart_calcs_clean'  + year + '.xlsx' ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate CCAG Calculations\n",
    "\n",
    "rp_calc = prep_data(abag, ccag_merged, rel)\n",
    "vta_final = landuse_calcs(rp_calc)\n",
    "\n",
    "geometry = vta_final['geometry']\n",
    "crs = mtc_taz.crs\n",
    "geo_df = gpd.GeoDataFrame(vta_final, crs=crs, geometry=geometry)\n",
    "\n",
    "geo_df.head()\n",
    "geo_df.to_file('abag_2010_ccag_dist')\n",
    "\n",
    "del vta_final['geometry']\n",
    "vta_final.to_csv('ccag_final_abag_2010.csv',index=False)\n",
    "vta_final.to_excel('ccag_final_abag_2010.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate VTA Calculations\n",
    "\n",
    "rp_calc = prep_data(abag, vta_taz)\n",
    "vta_final = landuse_calcs(rp_calc)\n",
    "\n",
    "geometry = vta_final['geometry']\n",
    "crs = mtc_taz.crs\n",
    "geo_df = gpd.GeoDataFrame(vta_final, crs=crs, geometry=geometry)\n",
    "\n",
    "\n",
    "geo_df.head()\n",
    "geo_df.to_file('abag_2010_vta_dist')\n",
    "\n",
    "del vta_final['geometry']\n",
    "vta_final.to_csv('vta_final_abag_2010.csv',index=False)\n",
    "vta_final.to_excel('vta_final_abag_2010.xlsx',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
